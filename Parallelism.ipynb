{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9474190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# load the boston data set\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca43ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.43571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>5.344</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>23.09</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.79041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>6.122</td>\n",
       "      <td>52.8</td>\n",
       "      <td>2.6403</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.98</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.19802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>6.182</td>\n",
       "      <td>42.4</td>\n",
       "      <td>3.9454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>393.63</td>\n",
       "      <td>9.47</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>11.81230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>6.824</td>\n",
       "      <td>76.5</td>\n",
       "      <td>1.7940</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>48.45</td>\n",
       "      <td>22.74</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.05023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>5.706</td>\n",
       "      <td>28.4</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>394.02</td>\n",
       "      <td>12.43</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS     NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "209   0.43571   0.0  10.59   1.0  0.4890  5.344  100.0  3.8750   4.0  277.0   \n",
       "311   0.79041   0.0   9.90   0.0  0.5440  6.122   52.8  2.6403   4.0  304.0   \n",
       "215   0.19802   0.0  10.59   0.0  0.4890  6.182   42.4  3.9454   4.0  277.0   \n",
       "419  11.81230   0.0  18.10   0.0  0.7180  6.824   76.5  1.7940  24.0  666.0   \n",
       "331   0.05023  35.0   6.06   0.0  0.4379  5.706   28.4  6.6407   1.0  304.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "209     18.6  396.90  23.09    20.0  \n",
       "311     18.4  396.90   5.98    22.1  \n",
       "215     18.6  393.63   9.47    25.0  \n",
       "419     20.2   48.45  22.74     8.4  \n",
       "331     16.9  394.02  12.43    17.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to a Pandas Data Frame\n",
    "boston_pd = pd.DataFrame(data= np.c_[boston['data'],boston['target']],\n",
    "                         columns= np.append(boston['feature_names'],'target')\n",
    "                        ).sample(frac=1)\n",
    "boston_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91175686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-sqaured: 0.7522181881375871\n",
      "MAE: 3.157415008267265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "#split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split into data and label arrays \n",
    "y = boston_pd['target']\n",
    "X = boston_pd.drop(['target'], axis=1)\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,\n",
    "                                                  train_size =0.80,\n",
    "                                                  test_size=0.2,\n",
    "                                                  shuffle=False,\n",
    "                                                  random_state=0)\n",
    "\n",
    "\n",
    "# train a classifier \n",
    "lr = LinearRegression()\n",
    "model = lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# error metrics\n",
    "r = pearsonr(y_pred, y_test)\n",
    "mae = sum(abs(y_pred - y_test))/len(y_test)\n",
    "print(\"R-sqaured: \" + str(r[0]**2))\n",
    "print(\"MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd39cd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CRIM=0.43571, ZN=0.0, INDUS=10.59, CHAS=1.0, NOX=0.489, RM=5.344, AGE=100.0, DIS=3.875, RAD=4.0, TAX=277.0, PTRATIO=18.6, B=396.9, LSTAT=23.09, target=20.0),\n",
       " Row(CRIM=0.79041, ZN=0.0, INDUS=9.9, CHAS=0.0, NOX=0.544, RM=6.122, AGE=52.8, DIS=2.6403, RAD=4.0, TAX=304.0, PTRATIO=18.4, B=396.9, LSTAT=5.98, target=22.1),\n",
       " Row(CRIM=0.19802, ZN=0.0, INDUS=10.59, CHAS=0.0, NOX=0.489, RM=6.182, AGE=42.4, DIS=3.9454, RAD=4.0, TAX=277.0, PTRATIO=18.6, B=393.63, LSTAT=9.47, target=25.0),\n",
       " Row(CRIM=11.8123, ZN=0.0, INDUS=18.1, CHAS=0.0, NOX=0.718, RM=6.824, AGE=76.5, DIS=1.794, RAD=24.0, TAX=666.0, PTRATIO=20.2, B=48.45, LSTAT=22.74, target=8.4),\n",
       " Row(CRIM=0.05023, ZN=35.0, INDUS=6.06, CHAS=0.0, NOX=0.4379, RM=5.706, AGE=28.4, DIS=6.6407, RAD=1.0, TAX=304.0, PTRATIO=16.9, B=394.02, LSTAT=12.43, target=17.1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# convert to a Spark data frame\n",
    "boston_sp = spark.createDataFrame(boston_pd)\n",
    "display(boston_sp.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f55e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# split into training and test spark data frames\n",
    "boston_train = spark.createDataFrame(boston_pd[:400])\n",
    "boston_test = spark.createDataFrame(boston_pd[400:])\n",
    "\n",
    "# convert to vector representation for MLlib\n",
    "assembler = VectorAssembler(inputCols= boston_train.schema.names[:(boston_pd.shape[1] - 1)],  outputCol=\"features\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120d0612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([0.4357, 0.0, 10.59, 1.0, 0.489, 5.344, 100.0, 3.875, 4.0, 277.0, 18.6, 396.9, 23.09]), target=20.0),\n",
       " Row(features=DenseVector([0.7904, 0.0, 9.9, 0.0, 0.544, 6.122, 52.8, 2.6403, 4.0, 304.0, 18.4, 396.9, 5.98]), target=22.1),\n",
       " Row(features=DenseVector([0.198, 0.0, 10.59, 0.0, 0.489, 6.182, 42.4, 3.9454, 4.0, 277.0, 18.6, 393.63, 9.47]), target=25.0),\n",
       " Row(features=DenseVector([11.8123, 0.0, 18.1, 0.0, 0.718, 6.824, 76.5, 1.794, 24.0, 666.0, 20.2, 48.45, 22.74]), target=8.4),\n",
       " Row(features=DenseVector([0.0502, 35.0, 6.06, 0.0, 0.4379, 5.706, 28.4, 6.6407, 1.0, 304.0, 16.9, 394.02, 12.43]), target=17.1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boston_train = assembler.transform(boston_train).select('features', 'target') \n",
    "boston_test = assembler.transform(boston_test).select('features', 'target') \n",
    "display(boston_train.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5ac1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-sqaured: 0.7494373900890622\n"
     ]
    }
   ],
   "source": [
    "# linear regresion with Spark\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# linear regression \n",
    "lr = LinearRegression(maxIter=10, regParam=0.1, elasticNetParam=0.5, labelCol=\"target\")\n",
    "\n",
    "# Fit the model\n",
    "model = lr.fit(boston_train)\n",
    "boston_pred = model.transform(boston_test)\n",
    "\n",
    "# calculate results \n",
    "r = boston_pred.stat.corr(\"prediction\", \"target\")\n",
    "print(\"R-sqaured: \" + str(r**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26483241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-sqaured: 0.7371479310298303\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CrossValidatorModel' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Coding\\Paralelism.ipynb Celda 8\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Coding/Paralelism.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m r \u001b[39m=\u001b[39m boston_pred\u001b[39m.\u001b[39mstat\u001b[39m.\u001b[39mcorr(\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Coding/Paralelism.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mR-sqaured: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(r\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Coding/Paralelism.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m cvModel\u001b[39m.\u001b[39;49mbest_params_\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CrossValidatorModel' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "crossval = CrossValidator(estimator=LinearRegression(labelCol = \"target\"),  \n",
    "                         estimatorParamMaps=ParamGridBuilder().addGrid(\n",
    "                           LinearRegression.elasticNetParam, [0, 0.5, 1.0]).build(),\n",
    "                         evaluator=RegressionEvaluator(\n",
    "                           labelCol = \"target\", metricName = \"r2\"),\n",
    "                         numFolds=10)\n",
    "\n",
    "# cross validate the model and select the best fit\n",
    "cvModel = crossval.fit(boston_train) \n",
    "model = cvModel.bestModel\n",
    "\n",
    "# calculate results \n",
    "boston_pred = model.transform(boston_test)\n",
    "r = boston_pred.stat.corr(\"prediction\", \"target\")\n",
    "print(\"R-sqaured: \" + str(r**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a384a5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 0.9003868500739229], [20, 0.8968407869468661], [50, 0.8963772265804383]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn version \n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# allow up to 5 concurrent threads\n",
    "pool = ThreadPool(5)\n",
    "\n",
    "# hyperparameters to test out (n_trees)\n",
    "parameters = [ 10, 20, 50]\n",
    "\n",
    "# define a function to train a RF model and return metrics \n",
    "def sklearn_random_forest(trees, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # train a random forest regressor with the specified number of trees\n",
    "    rf= RFR(n_estimators = trees)\n",
    "    model = rf.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    r = pearsonr(y_pred, y_test)\n",
    "\n",
    "    # return the number of trees, and the R value \n",
    "    return [trees, r[0]**2]  \n",
    "\n",
    "# run the tasks \n",
    "pool.map(lambda trees: sklearn_random_forest(trees, X_train,\n",
    "                                           X_test, y_train, y_test), parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "566ba218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 0.8498726041898135], [20, 0.8284686226121398], [50, 0.8249331388684156]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark version\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# define a function to train a RF model and return metrics \n",
    "def mllib_random_forest(trees, boston_train, boston_test):\n",
    "\n",
    "    # train a random forest regressor with the specified number of trees\n",
    "    rf = RandomForestRegressor(numTrees = trees, labelCol=\"target\")\n",
    "    model = rf.fit(boston_train)\n",
    "\n",
    "    # make predictions\n",
    "    boston_pred = model.transform(boston_test)\n",
    "    r = boston_pred.stat.corr(\"prediction\", \"target\")\n",
    "\n",
    "    # return the number of trees, and the R value \n",
    "    return [trees, r**2]\n",
    "  \n",
    "# run the tasks \n",
    "pool.map(lambda trees: mllib_random_forest(trees, boston_train, boston_test), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4d01b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schav\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\pandas\\group_ops.py:98: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(trees=11, r_squared=0.9266122436888398), Row(trees=20, r_squared=0.926764044487551), Row(trees=50, r_squared=0.9346669196092909)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# setup the spark data frame as a table\n",
    "boston_sp.createOrReplaceTempView(\"boston\")\n",
    "\n",
    "# add train/test label and expand the data set by 3x (each num trees parameter)\n",
    "full_df = spark.sql(\"\"\"\n",
    "  select *\n",
    "  from (\n",
    "    select *, case when rand() < 0.8 then 1 else 0 end as training \n",
    "    from boston\n",
    "  ) b\n",
    "  cross join (\n",
    "      select 11 as trees union all select 20 as trees union all select 50 as trees)\n",
    "\"\"\")\n",
    "\n",
    "schema = StructType([StructField('trees', LongType(), True),\n",
    "                     StructField('r_squared', DoubleType(), True)])  \n",
    "\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def train_RF(boston_pd):\n",
    "    trees = boston_pd['trees'].unique()[0]\n",
    "\n",
    "    # get the train and test groups \n",
    "    boston_train = boston_pd[boston_pd['training'] == 1]\n",
    "    boston_test = boston_pd[boston_pd['training'] == 0] \n",
    "        \n",
    "    # create data and label groups \n",
    "    y_train = boston_train['target']\n",
    "    X_train = boston_train.drop(['target'], axis=1)\n",
    "    y_test = boston_test['target']\n",
    "    X_test = boston_test.drop(['target'], axis=1)\n",
    "   \n",
    "    # train a classifier \n",
    "    rf= RFR(n_estimators = trees)\n",
    "    model = rf.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    r = pearsonr(y_pred, y_test)\n",
    "    \n",
    "    # return the number of trees, and the R value \n",
    "    return pd.DataFrame({'trees': trees, 'r_squared': (r[0]**2)}, index=[0])\n",
    "  \n",
    "# use the Pandas UDF\n",
    "results = full_df.groupby('trees').apply(train_RF)\n",
    "\n",
    "# print the results \n",
    "print(results.take(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0ce7b47cb929c1ad68efe0a6a5b5377fb9c2267c959449bcdc19182d094ee29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
